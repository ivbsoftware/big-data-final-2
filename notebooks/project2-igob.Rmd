---
title: "R Notebook"
output: html_notebook
---

# Loading Wine datasets

```{r}
set.seed(42)
library(ggplot2)
library(reshape2)
library(plyr)
library(readr)
library(xtable)
library(fpc)
library(data.table)
library(ggplot2)
```

## Datasets description

```
For more information, read [Cortez et al., 2009]. 
Input variables (based on physicochemical tests): 

1 - fixed acidity        (FA)
2 - volatile acidity     (VA)
3 - citric acid          (CA)
4 - residual sugar       (RS)
5 - chlorides            (CH)
6 - free sulfur dioxide  (FSD)
7 - total sulfur dioxide (TSD)
8 - density              (DEN)
9 - pH                   (pH)
10 - sulphates           (SUL)
11 - alcohol             (ALC) 

Output variable (based on sensory data): 
12 - quality (score between 0 and 10) - (QLT)
```

## Reading red wines dataset

```{r}
wines_red_data <- 
  read.csv(
    "http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv",
    sep=";", 
    header = TRUE, 
    col.names = c("FA","VA","CA","RS","CH","FSD","TSD","DEN","pH","SUL","ALC","QLT"))
```
```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, results='asis'}
options(xtable.floating = TRUE)
options(xtable.timestamp = "")
options(xtable.comment = FALSE)
print(xtable(summary(wines_red_data[,1:6])), include.rownames = FALSE)
print(xtable(summary(wines_red_data[,7:12]), 
  caption = "\\tt Red Wines Dataset Summary", label = "table:sum_rw"),
  include.rownames = FALSE)
```

## Reading white wines dataset

```{r}
wines_white_data <- 
  read.csv(
    "http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv",
    sep=";", 
    header = TRUE, 
    col.names = c("FA","VA","CA","RS","CH","FSD","TSD","DEN","pH","SUL","ALC","QLT"))
```
```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, results='asis'}
options(xtable.floating = TRUE)
options(xtable.timestamp = "")
options(xtable.comment = FALSE)
print(xtable(summary(wines_white_data[,1:6])), include.rownames = FALSE)
print(xtable(summary(wines_white_data[,7:12]), 
  caption = "\\tt White Wines Dataset Summary", label = "table:sum_rw"),
  include.rownames = FALSE)
```

# Inspecting the data
## Checking red wines orrelation matrix
```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, results='asis'}
cor_rw <- cor(wines_red_data)
table_cor_rw <- xtable(cor_rw, 
  caption = "\\tt Red Wines Quality Dataset Correlation Matrix", label = "table:table_cor_rw")
print(table_cor_rw, scalebox=1)
```


# Clustering
## Red whines dataset normalizing

Normalizing red whine dataset in preparation to clustering
```{r}
wines_red_data.std <- scale(wines_red_data[1:11])
head(wines_red_data.std)
```

Print the normilized red wine dataset summary
```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, results='asis'}
options(xtable.floating = TRUE)
options(xtable.timestamp = "")
options(xtable.comment = FALSE)
print(xtable(summary(wines_red_data.std[,1:6])), include.rownames = FALSE)
print(xtable(summary(wines_red_data.std[,7:11]), 
  caption = "\\tt Normalized White Wines Dataset Summary", label = "table:sum_rw"),
  include.rownames = FALSE)
```

## Red wine dataset clustering K-means
```{r}
k.means.red.fit <- kmeans(wines_red_data.std, 2,iter.max = 1000)
attributes(k.means.red.fit)
k.means.red.fit$centers
k.means.red.fit$cluster
k.means.red.fit$size
```


```{r}
library(cluster)
clusplot(wines_red_data.std, k.means.red.fit$cluster, main='2D representation of the Cluster solution',
         color=TRUE, shade=TRUE,
         labels=2, lines=0)
```
```{r}
#In order to evaluate the clustering performance we build a confusion matrix:
    table(wines_red_data[,12],k.means.red.fit$cluster)
```

$ Hierarchical Clustering

```{r}
#Hierarchical clustering:
#Hierarchical methods use a distance matrix as an input for the clustering algorithm. 
#The choice of an appropriate metric will influence the shape of the clusters, as some element
#may be close to one another according to one distance and farther away according to another.

d <- dist(wines_red_data.std, method = "euclidean") # Euclidean distance matrix.
#We use the Euclidean distance as an input for the clustering algorithm 
#(Wardâs minimum variance criterion minimizes the total within-cluster variance):
  
H.fit <- hclust(d, method="ward.D2")

#The clustering output can be displayed in a dendrogram

plot(H.fit) # display dendogram
groups <- cutree(H.fit, k=11) # cut tree into 3 clusters

# draw dendogram with red borders around the 3 clusters
rect.hclust(H.fit, k=11, border="red") 

#The clustering performance can be evaluated with the aid of a confusion matrix as follows:
  
table(wines_red_data[,12],groups)
```

